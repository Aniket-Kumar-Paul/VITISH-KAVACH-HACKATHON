{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5092ca",
   "metadata": {},
   "source": [
    "# Face Recognition with Siamese Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae5d9319-0ef9-44fa-9d07-7fcd519ee4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "torch     : 2.0.0\n",
      "matplotlib: 3.6.3\n",
      "numpy     : 1.23.5\n",
      "seaborn   : 0.12.2\n",
      "pandas    : 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import models\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -p torch,matplotlib,numpy,seaborn,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acda99",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d70eed0-08f3-4966-bd79-42d11dc85fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    seed   = 42\n",
    "    project_name = 'frs-kavach'\n",
    "    exp_name = 'siamese-frs'\n",
    "    base_model    = 'convnext_base'\n",
    "    train_bs      = 8\n",
    "    valid_bs      = 2 * train_bs\n",
    "    image_size    = [112, 112]\n",
    "    comment       = f'basemodel-{base_model}|img_size-{image_size[0]}x{image_size[1]}'\n",
    "    epochs        = 10\n",
    "    \n",
    "    optimizer     = 'Adam'\n",
    "    learning_rate = 3e-4\n",
    "    rho           = 0.9\n",
    "    eps           = 1e-6\n",
    "    lr_decay      = 0\n",
    "    betas         = (0.9, 0.999)\n",
    "    momentum      = 0\n",
    "    alpha         = 0.99\n",
    "    \n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    weight_decay  = 1e-6\n",
    "    \n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    num_folds     = 5\n",
    "    num_classes   = None\n",
    "\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iteration_num = 1\n",
    "\n",
    "    train_path    = '../../artifacts/archive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37818c62",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f1d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):    \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('>>> SEEDING DONE')\n",
    "    \n",
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d3e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer: optim):\n",
    "    '''\n",
    "    A method which returns the required schedulers.\n",
    "        - Extracted from Awsaf's Kaggle.\n",
    "    '''\n",
    "    if config.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimizer, \n",
    "            T_max=config.T_max, \n",
    "            eta_min=config.min_lr\n",
    "        )\n",
    "    elif config.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer=optimizer, \n",
    "            T_0=config.T_0, \n",
    "            eta_min=config.eta_min\n",
    "        )\n",
    "    elif config.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer, \n",
    "            mode='min',\n",
    "            factor=0.1, \n",
    "            patience=10, \n",
    "            threshold=0.0001, \n",
    "            min_lr=config.min_lr\n",
    "        )\n",
    "    elif config.scheduler == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(\n",
    "            optimizer=optimizer, \n",
    "            gamma=0.85\n",
    "        )\n",
    "    elif config.scheduler is None:\n",
    "        scheduler = None\n",
    "    else:\n",
    "        raise NotImplementedError(\"The Scheduler you have asked has not been implemented\")\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8fdd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model: nn.Module):\n",
    "    '''\n",
    "    Returns the optimizer based on the config files.\n",
    "    '''\n",
    "    if config.optimizer == 'Adadelta':\n",
    "        optimizer = optim.Adadelta(\n",
    "            model.parameters(), \n",
    "            lr=config.learning_rate,\n",
    "            rho=config.rho, \n",
    "            eps=config.eps\n",
    "        )\n",
    "    elif config.optimizer == 'Adagrad':\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(), \n",
    "            lr=config.learning_rate, \n",
    "            lr_decay=config.lr_decay,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "    elif config.optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate, \n",
    "            betas=config.betas, \n",
    "            eps=config.eps\n",
    "        )\n",
    "    elif config.optimizer == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(),\n",
    "            lr=config.learning_rate, \n",
    "            alpha=config.alpha, \n",
    "            eps=config.eps, \n",
    "            weight_decay=config.weight_decay, \n",
    "            momentum=config.momentum\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"The optimizer {config.optimizer} has not been implemented.\")\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72433ce3",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c346b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "# Plotting data\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, imgFo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
